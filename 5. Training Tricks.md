1. Gradient clipping / Gradient Normalization converge arbitrarily faster then gradient descent with fixed step size. (Accroding a [paper](https://openreview.net/pdf?id=BJgnXpVYwS) on ICLR 2020)
